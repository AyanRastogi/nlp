{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4s9vZxttcStb"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365,
     "referenced_widgets": [
      "5226bc36e740494086b895f58dcdc848",
      "a91ae6b4c3c24828b4ce76fff922ad1b",
      "e07462e6d8e743318e08348bc9596075",
      "b571af04760b4768bc826f1851114acf",
      "1e92e75b8040476c939dc146d796c995",
      "d7e3382c8b6e431eb37a8aade8822d1c",
      "87d1dbe94f14427b95bcf9ecd3f6a90a",
      "bc9f7ac52db94657bea813004c6ef647",
      "58f4fc42d47d4f2e9b30979f96934620",
      "af0af286ca454445bf3c59986dcaba53",
      "22ef3e0264634c318e89c7aff84236fc",
      "e905dd51ae0e4a4ca072cba7c43b7cbc",
      "0b196b51a53244bf96d823beda2bf9a0",
      "0df50073ec234b778109568b52cd12a6",
      "bcc3d1c6fe1e4960bf6f7c28d199913b",
      "c38790dcf6044acd8f269cdb22955768",
      "f373da00512f439f905d9d7463816c9b",
      "640bc8db146f4ccdac6df08bf45e2808",
      "87ac340aadfc4f7a9028dbece6649025",
      "67eed92e61bf49e9b3c8977367a47bc4",
      "2505e88df17443d8ada784516a2b2b92",
      "1263d4c19eea4a8a9470bf334fadb4b0",
      "49ba40d7c1144227873c0b789d4f9a9a",
      "ea02773e765742f38e4e896b9d1cfa40",
      "375b8f4598fd4e0db051766273d778b8",
      "74f8b88899b14de2bde0bc1322e3af10",
      "f6ae2b95fee5455a9fe2d5f9b24e9c00",
      "80eb73f656874c609d0a9e0f8c0d9638",
      "0ee2f6e5ff7740bfb1307bb51add1deb",
      "90c2d690a38a488ca0f77215a673857a",
      "7708d62cfdc844d08097b013d8ba0439",
      "f590e00ea88b441983dfb6f71f9df9ae",
      "39dfecfea9934c2f978f446fbde80c61",
      "8f4659c5049a49a1a442261342532e9a",
      "14e6c38f838b4258a6337be23fff3074",
      "3f7ff2258c6b4b5aaaf9fcc9bd392f11",
      "ccb834a46e0644eaaa0797550d9295a8",
      "c963e2887d9241498b1039158e71d011",
      "7ca61d4a942c47a5b95882b987fb9c58",
      "5ea1728986b34487bf615482cdc0d58f",
      "4900c563e61e40bab0e1aff23396d35d",
      "9ff22647ed3644839e723e96498dc171",
      "0bf6a9b3b3044232af32bc2b8cdb6fd0",
      "0559d6ef29474286a6bb4ac314e03313",
      "60294a4564f6472abdb25c400c8c2bb3",
      "530b19fd59a540018f7ceac8a48a0a81",
      "3cd1a4b8e6064c149561ecac9429e796",
      "51a5d35aac59403e845817b8f06f48f8",
      "19f948a3101b44cea0cb336ab0324c44",
      "452198d6f34d41d58ba0f45e192858b5",
      "9aadabcf863947dfac9002dff02c99bb",
      "35f6e172ee494d4b94204457189e1f0e",
      "e6c6abf2564348cea74b3548017bfeaf",
      "b8fb1351b4f641b1ab5344ca636bb2a3",
      "44a7941b70954c8d9e654740de498e0e",
      "f46f2e897656496a925d206963b5d330",
      "4122224fb2a14b5bb883215575271ece",
      "7c81d9849f3143348b36cbe6cc87a1ff",
      "59a872835565403a876d25f60cedf397",
      "c50d3dd9747b45518954ef3936be428b",
      "5a813f1a9ef843f99b7f6f1d714725fd",
      "fc8f9b881a014c58910cc97a2482ef31",
      "97ece13ca13d40adba3dd7de321a6e6b",
      "2ee5b1dbde7a4c91958b3c3def24da0a",
      "6c69145a37594c9b86c133b5fb8f23bb",
      "51b629068b004bb1afaddc0a493852b7",
      "f28248fcf81c43b9ac79ca3e4b0ab19d",
      "d28ada4c312a4cd098eda361e5564162",
      "d03361c465e24674bcef8bfbc5e4bb00",
      "ebca7ecf10c44da48eac2c1ef4ef7228",
      "41a69c2753b34c2e8483b38295916489",
      "d28c449511964beea0fe45475b32bc6a",
      "cb6aceb9cd3048bc881ccf1ae259f376",
      "d116655f01c74bb686cf77d22fad4015",
      "ff4cb1b001c64c5a995f3ccb31c7e529",
      "a6cac18187aa4b8db77a0fdf3e8bab36",
      "07bfa3bd4524431bb0528dc1cbe2a1ac"
     ]
    },
    "id": "8XEaUVblcfcD",
    "outputId": "d083aff8-edcb-440f-a9a4-7786a05729f2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5226bc36e740494086b895f58dcdc848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e905dd51ae0e4a4ca072cba7c43b7cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ba40d7c1144227873c0b789d4f9a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f4659c5049a49a1a442261342532e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60294a4564f6472abdb25c400c8c2bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46f2e897656496a925d206963b5d330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f28248fcf81c43b9ac79ca3e4b0ab19d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"gpt2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IzjLa8LbcwtV"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def generate_continuation(input_text, max_new_tokens=50):\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "    # Set attention mask explicitly\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "    # Generate continuation\n",
    "    outputs = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,       # Sampling introduces variation\n",
    "        top_k=50,             # Limits to top 50 tokens to sample from\n",
    "        top_p=0.95,           # Nucleus sampling\n",
    "        temperature=0.9,      # Higher temp = more randomness\n",
    "        pad_token_id=tokenizer.eos_token_id  # Avoid warning\n",
    "    )\n",
    "\n",
    "    # Decode and clean\n",
    "    raw_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Remove unusual unicode characters (emojis, Korean chars etc.)\n",
    "    cleaned_text = re.sub(r'[^\\x00-\\x7F]+', ' ', raw_text)\n",
    "    cleaned_text = re.sub(' +', ' ', cleaned_text)  # Clean extra spaces\n",
    "\n",
    "    return cleaned_text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CotyzorodIaH",
    "outputId": "2c75c1a3-5518-41a7-fb19-5275f62249d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a sentence: aashray is weak in english\n",
      "\n",
      "Generated Text:\n",
      " aashray is weak in english\n",
      "\n",
      "b. The following paragraphs are incorrect (from a previous version of this page):\n",
      "\n",
      "\"It is true that (Konami) did not make him, but his performance is still not a very good thing for him (Kon\n"
     ]
    }
   ],
   "source": [
    "input_sentence = input(\"Enter a sentence: \")\n",
    "continued = generate_continuation(input_sentence, max_new_tokens=50)\n",
    "print(\"\\nGenerated Text:\\n\", continued)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Lhtl12FdLtO",
    "outputId": "f8a3743a-5fb5-4e93-c162-99333ef819e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: nbstripout: command not found\n"
     ]
    }
   ],
   "source": [
    "!nbstripout textgen01.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "h2qKF6LqBE-G"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
